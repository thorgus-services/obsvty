# ðŸ•µï¸â€â™‚ï¸ Obsvty â€” Observability with Code Context

> **Observability tools tell you _what broke_.  
> Obsvty shows you _why it broke_ and _how to fix it_ â€” based on your code.**

**Obsvty** is an **open-source** platform that connects observability data (logs, metrics, traces) with code changes and language models (LLMs) to generate **actionable, contextual, and secure insights**.

All this with:
- ðŸ§© **Modular architecture** â€” use any LLM, version control, or alert destination.
- ðŸ”’ **Privacy-first** â€” sensitive data never leaves your environment.
- ðŸ“¦ **Auto technical documentation** â€” your docs update as your code and infra change.
- ðŸŒ± **Easy to run and contribute** â€” `docker-compose up` and you're set.

---

## ðŸ” Why Obsvty?

Most observability tools stop at the question:  
> _â€œWhere is the error?â€_

But engineers need to know:  
> _â€œWhich commit caused this? Which line of code should I review? What is the practical fix suggestion?â€_

**Obsvty bridges this gap** by correlating:
- **Traces/logs (OTLP)** â†” **Commits/PRs** â†” **LLM Suggestions**

### Example of generated insight:
```markdown
ðŸ” Detected insight:
- Metric: average latency of /checkout rose from 120ms â†’ 480ms
- Commit: d34db33f (added synchronous card validation)
- Suggestion (LLM): â€œMove validation to an async queue. See example in docs/async-payment.mdâ€
- Alert sent to #eng-alerts (Slack)
```

This is **smart observability** â€” not just data, but **action**.

---

## ðŸ§± Project Status (MVP v0.1 â€“ â€œInsight Loopâ€)

We are building the **first functional end-to-end flow**:

```
[OTLP] â†’ [Compression + Sanitization] â†’ [Modular LLM] â†’ [Alert + Doc + Chat]
                     â†‘
           [GitHub: commit, PR, diff]
```

### âœ… MVP Success Criteria:
1. You send traces/logs via OTLP.
2. Receive a Slack alert with a commit-contextualized suggestion.
3. Access a chat (Streamlit) with all the context: trace + code + recommendation.
4. Confirm that **no sensitive data** was sent to the LLM.
5. All runs locally with `docker-compose up`.

---

## ðŸ› ï¸ Technologies & Architecture

- **Language**: Python (3.10+)
- **Ingestion**: OTLP gRPC (OpenTelemetry)
- **Storage**: DuckDB (lightweight, no external dependencies)
- **LLM**: Any OpenAI-compatible provider (Ollama, OpenAI, Anthropic, etc.)
- **Frontend**: Streamlit (fast, iterative prototype)
- **Extensibility**: Abstract interfaces for plugins (Git, LLM, Alerts, Docs)

### Main interfaces (in `obsvty/ports/`):
```python
class GitProvider(ABC): ...
class LLMEngine(ABC): ...
class AlertPlugin(ABC): ...
class DocGenerator(ABC): ...
```

Want to add support for GitLab? Confluence? A new local model? Just implement the interface.

---

## ðŸ—ºï¸ Public Roadmap

| Phase | Name | Goal |
|-------|------|------|
| **M0** | Bootstrapping | Repo, CI, modular structure |
| **M1** | Observability Core | OTLP + compression + detection |
| **M2** | AI Brain | Secure LLM + modular workflow |
| **M3** | Context Connect | GitHub + Slack + auto doc |
| **M4** | Insight Chat | UI with contextual chat |
| **M5** | First Release | Community launch |

---

## ðŸš€ How to Run Locally (coming soon)

```bash
git clone https://github.com/thorgus-services/obsvty.git
cd obsvty
docker-compose up
```

> âš ï¸ **Still under construction!** We are in phase **M0/M1**. The runnable version will be released in the coming weeks.

---

## ðŸ¤ Want to Contribute?

Obsvty is born as a project from the community, for the community.

### You can:
- ðŸ§ª Test the MVP as soon as it's released
- ðŸ§© Write a plugin (e.g.: GitLab, Jira, Confluence)
- ðŸ§  Suggest improvements for trace compression or anomaly detection
- ðŸ“ Improve documentation or write tutorials

See [CONTRIBUTING.md](./docs/CONTRIBUTING.md) to get started.

---

## ðŸ“œ License

Apache License 2.0 â€” see [LICENSE](./LICENSE).

---

## ðŸ“£ Contact Us

- Open an [Issue](https://github.com/thorgus-services/obsvty/issues)
- [Contact me directly](https://www.linkedin.com/in/fernandojr-dev/)

---

> **Obsvty**: because understanding the *why* is as important as seeing the *what*.